{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_VanGogh_Styles_CNN.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"2JBB6Ro2ahnJ","colab_type":"code","colab":{}},"cell_type":"code","source":["#imports\n","import os\n","import numpy as np\n","import scipy.misc\n","import scipy.io\n","import math\n","import tensorflow as tf\n","from sys import stderr\n","from functools import reduce\n","import time  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qby-NJyGalXu","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","## Inputs \n","file_content_image = 'Ashish1.jpg' \n","file_style_image = 'VanGoghVincent.jpg'   \n","#file_style_image = 'Afremov _rain_princess.jpg'   "],"execution_count":0,"outputs":[]},{"metadata":{"id":"aYQ3onDHalnt","colab_type":"code","colab":{}},"cell_type":"code","source":["## Parameters \n","input_noise = 0.1     # proportion noise to apply to content image\n","weight_style = 2e2 "],"execution_count":0,"outputs":[]},{"metadata":{"id":"m2rFO4Akalu4","colab_type":"code","colab":{}},"cell_type":"code","source":["## Layers\n","layer_content = 'conv4_2' \n","layers_style = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n","layers_style_weights = [0.3,0.3,0.3,0.3,0.3]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3Mkltkx9alyl","colab_type":"code","colab":{}},"cell_type":"code","source":["## VGG19 model\n","path_VGG19 = 'imagenet-vgg-verydeep-19.mat'\n","# VGG19 mean for standardisation (RGB)\n","VGG19_mean = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aRpvZCSOal2d","colab_type":"code","colab":{}},"cell_type":"code","source":["## Reporting & writing checkpoint images\n","# NB. the total # of iterations run will be n_checkpoints * n_iterations_checkpoint\n","n_checkpoints = 10            # number of checkpoints\n","n_iterations_checkpoint = 10   # learning iterations per checkpoint\n","path_output = 'output'  # directory to write checkpoint images into"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LwMWBcxCal5W","colab_type":"code","colab":{}},"cell_type":"code","source":["### Helper functions\n","def imread(path):\n","    return scipy.misc.imread(path).astype(np.float)   # returns RGB format\n","\n","def imsave(path, img):\n","    img = np.clip(img, 0, 255).astype(np.uint8)\n","    scipy.misc.imsave(path, img)\n","    \n","def imgpreprocess(image):\n","    image = image[np.newaxis,:,:,:]\n","    return image - VGG19_mean\n","\n","def imgunprocess(image):\n","    temp = image + VGG19_mean\n","    return temp[0] \n","\n","# function to convert 2D greyscale to 3D RGB\n","def to_rgb(im):\n","    w, h = im.shape\n","    ret = np.empty((w, h, 3), dtype=np.uint8)\n","    ret[:, :, 0] = im\n","    ret[:, :, 1] = im\n","    ret[:, :, 2] = im\n","    return ret\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zp1aBaPVal9w","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","### Preprocessing\n","# create output directory\n","if not os.path.exists(path_output):\n","    os.mkdir(path_output)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7dJZNLJtbDsn","colab_type":"code","outputId":"10035806-a064-4659-cae6-72b119483f9f","executionInfo":{"status":"ok","timestamp":1543507798693,"user_tz":360,"elapsed":369,"user":{"displayName":"Madhavi Polisetti","photoUrl":"https://lh4.googleusercontent.com/-fKBeYNGvnLg/AAAAAAAAAAI/AAAAAAAAAB0/XI7prIGym90/s64/photo.jpg","userId":"07850492719441618151"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["# read in images\n","img_content = imread(file_content_image) \n","img_style = imread(file_style_image) "],"execution_count":96,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n","`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imread`` instead.\n","  \n"],"name":"stderr"}]},{"metadata":{"id":"29x7tLyqbFfY","colab_type":"code","outputId":"46741b81-4c9a-41dd-a35c-ca52b894959e","executionInfo":{"status":"ok","timestamp":1543507798875,"user_tz":360,"elapsed":379,"user":{"displayName":"Madhavi Polisetti","photoUrl":"https://lh4.googleusercontent.com/-fKBeYNGvnLg/AAAAAAAAAAI/AAAAAAAAAB0/XI7prIGym90/s64/photo.jpg","userId":"07850492719441618151"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["# convert if greyscale\n","if len(img_content.shape)==2:\n","    img_content = to_rgb(img_content)\n","    \n","if len(img_style.shape)==2:\n","    img_style = to_rgb(img_style)\n","\n","print(img_content.shape)\n","print(img_style.shape)\n"],"execution_count":97,"outputs":[{"output_type":"stream","text":["(200, 200, 3)\n","(747, 1024, 3)\n"],"name":"stdout"}]},{"metadata":{"id":"-EXFs52ubJSg","colab_type":"code","outputId":"bb07f101-2170-412f-94f1-1abb5516a949","executionInfo":{"status":"ok","timestamp":1543507799201,"user_tz":360,"elapsed":559,"user":{"displayName":"Madhavi Polisetti","photoUrl":"https://lh4.googleusercontent.com/-fKBeYNGvnLg/AAAAAAAAAAI/AAAAAAAAAB0/XI7prIGym90/s64/photo.jpg","userId":"07850492719441618151"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["# resize style image to match content\n","img_style = scipy.misc.imresize(img_style, img_content.shape)"],"execution_count":98,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``skimage.transform.resize`` instead.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"metadata":{"id":"cSTqe6GsbLhI","colab_type":"code","colab":{}},"cell_type":"code","source":["# apply noise to create initial \"canvas\" \n","noise = np.random.uniform(\n","        img_content.mean()-img_content.std(), img_content.mean()+img_content.std(),\n","        (img_content.shape)).astype('float32')\n","img_initial = noise * input_noise + img_content * (1 - input_noise)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z5J1vGLpbNo4","colab_type":"code","colab":{}},"cell_type":"code","source":["# preprocess each\n","img_content = imgpreprocess(img_content)\n","img_style = imgpreprocess(img_style)\n","img_initial = imgpreprocess(img_initial)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mo601Ak7bSYg","colab_type":"code","colab":{}},"cell_type":"code","source":["#### BUILD VGG19 MODEL\n","## with thanks to http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n","\n","VGG19 = scipy.io.loadmat(path_VGG19)\n","VGG19_layers = VGG19['layers'][0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PwLGaSmSbUVZ","colab_type":"code","colab":{}},"cell_type":"code","source":["# help functions\n","def _conv2d_relu(prev_layer, n_layer, layer_name):\n","    # get weights for this layer:\n","    weights = VGG19_layers[n_layer][0][0][2][0][0]\n","    W = tf.constant(weights)\n","    bias = VGG19_layers[n_layer][0][0][2][0][1]\n","    b = tf.constant(np.reshape(bias, (bias.size)))\n","    # create a conv2d layer\n","    conv2d = tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b    \n","    # add a ReLU function and return\n","    return tf.nn.relu(conv2d)\n","\n","def _avgpool(prev_layer):\n","    return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AZJWZr3QbW-J","colab_type":"code","colab":{}},"cell_type":"code","source":["# Setup network\n","with tf.Session() as sess:\n","    a, h, w, d     = img_content.shape\n","    net = {}\n","    net['input']   = tf.Variable(np.zeros((a, h, w, d), dtype=np.float32))\n","    net['conv1_1']  = _conv2d_relu(net['input'], 0, 'conv1_1')\n","    net['conv1_2']  = _conv2d_relu(net['conv1_1'], 2, 'conv1_2')\n","    net['avgpool1'] = _avgpool(net['conv1_2'])\n","    net['conv2_1']  = _conv2d_relu(net['avgpool1'], 5, 'conv2_1')\n","    net['conv2_2']  = _conv2d_relu(net['conv2_1'], 7, 'conv2_2')\n","    net['avgpool2'] = _avgpool(net['conv2_2'])\n","    net['conv3_1']  = _conv2d_relu(net['avgpool2'], 10, 'conv3_1')\n","    net['conv3_2']  = _conv2d_relu(net['conv3_1'], 12, 'conv3_2')\n","    net['conv3_3']  = _conv2d_relu(net['conv3_2'], 14, 'conv3_3')\n","    net['conv3_4']  = _conv2d_relu(net['conv3_3'], 16, 'conv3_4')\n","    net['avgpool3'] = _avgpool(net['conv3_4'])\n","    net['conv4_1']  = _conv2d_relu(net['avgpool3'], 19, 'conv4_1')\n","    net['conv4_2']  = _conv2d_relu(net['conv4_1'], 21, 'conv4_2')     \n","    net['conv4_3']  = _conv2d_relu(net['conv4_2'], 23, 'conv4_3')\n","    net['conv4_4']  = _conv2d_relu(net['conv4_3'], 25, 'conv4_4')\n","    net['avgpool4'] = _avgpool(net['conv4_4'])\n","    net['conv5_1']  = _conv2d_relu(net['avgpool4'], 28, 'conv5_1')\n","    net['conv5_2']  = _conv2d_relu(net['conv5_1'], 30, 'conv5_2')\n","    net['conv5_3']  = _conv2d_relu(net['conv5_2'], 32, 'conv5_3')\n","    net['conv5_4']  = _conv2d_relu(net['conv5_3'], 34, 'conv5_4')\n","    net['avgpool5'] = _avgpool(net['conv5_4'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8J1ESczGbfqn","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","### CONTENT LOSS: FUNCTION TO CALCULATE AND INSTANTIATION\n","# with thanks to https://github.com/cysmith/neural-style-tf\n","\n","# Recode to be simpler: http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n","def content_layer_loss(p, x):\n","    _, h, w, d = [i.value for i in p.get_shape()]    # d: number of filters; h,w : height, width\n","    M = h * w \n","    N = d \n","    K = 1. / (2. * N**0.5 * M**0.5)\n","    loss = K * tf.reduce_sum(tf.pow((x - p), 2))\n","    return loss\n","\n","with tf.Session() as sess:\n","    sess.run(net['input'].assign(img_content))\n","    p = sess.run(net[layer_content])  # Get activation output for content layer\n","    x = net[layer_content]\n","    p = tf.convert_to_tensor(p)\n","    content_loss = content_layer_loss(p, x) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"6sAsGU1bbgZn","colab_type":"code","colab":{}},"cell_type":"code","source":["### STYLE LOSS: FUNCTION TO CALCULATE AND INSTANTIATION\n","\n","def style_layer_loss(a, x):\n","    _, h, w, d = [i.value for i in a.get_shape()]\n","    M = h * w \n","    N = d \n","    A = gram_matrix(a, M, N)\n","    G = gram_matrix(x, M, N)\n","    loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A), 2))\n","    return loss\n","\n","def gram_matrix(x, M, N):\n","    F = tf.reshape(x, (M, N))                   \n","    G = tf.matmul(tf.transpose(F), F)\n","    return G\n","\n","with tf.Session() as sess:\n","    sess.run(net['input'].assign(img_style))\n","    style_loss = 0.\n","    # style loss is calculated for each style layer and summed\n","    for layer, weight in zip(layers_style, layers_style_weights):\n","        a = sess.run(net[layer])\n","        x = net[layer]\n","        a = tf.convert_to_tensor(a)\n","        style_loss += style_layer_loss(a, x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fDORpT2vbjYh","colab_type":"code","outputId":"ca87bf1b-4539-464d-e043-9a3fc8ee7c0b","executionInfo":{"status":"ok","timestamp":1543508017247,"user_tz":360,"elapsed":217198,"user":{"displayName":"Madhavi Polisetti","photoUrl":"https://lh4.googleusercontent.com/-fKBeYNGvnLg/AAAAAAAAAAI/AAAAAAAAAB0/XI7prIGym90/s64/photo.jpg","userId":"07850492719441618151"}},"colab":{"base_uri":"https://localhost:8080/","height":1615}},"cell_type":"code","source":["### Define loss function and minimise\n","with tf.Session() as sess:\n","    # loss function\n","    L_total  = content_loss + weight_style * style_loss \n","    \n","    # instantiate optimiser\n","    optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n","      L_total, method='L-BFGS-B',\n","      options={'maxiter': n_iterations_checkpoint})\n","    \n","    init_op = tf.initialize_all_variables()\n","    sess.run(init_op)\n","    sess.run(net['input'].assign(img_initial))\n","    for i in range(1,n_checkpoints+1):\n","        # run optimisation\n","        optimizer.minimize(sess)\n","        \n","        ## print costs\n","        stderr.write('Iteration %d/%d\\n' % (i*n_iterations_checkpoint, n_checkpoints*n_iterations_checkpoint))\n","        stderr.write('  content loss: %g\\n' % sess.run(content_loss))\n","        stderr.write('    style loss: %g\\n' % sess.run(weight_style * style_loss))\n","        stderr.write('    total loss: %g\\n' % sess.run(L_total))\n","\n","        ## write image\n","        img_output = sess.run(net['input'])\n","        img_output = imgunprocess(img_output)\n","        timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n","        output_file = path_output+'/'+timestr+'_'+'%s.jpg' % (i*n_iterations_checkpoint)\n","        imsave(output_file, img_output)"],"execution_count":106,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 1921449984.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 15\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 10/100\n","  content loss: 1.80029e+07\n","    style loss: 1.90345e+09\n","    total loss: 1.92145e+09\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `imsave` is deprecated!\n","`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imwrite`` instead.\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 834497088.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 13\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 20/100\n","  content loss: 1.96258e+07\n","    style loss: 8.14871e+08\n","    total loss: 8.34497e+08\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 494306976.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 13\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 30/100\n","  content loss: 2.02924e+07\n","    style loss: 4.74015e+08\n","    total loss: 4.94307e+08\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 397212960.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 13\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 40/100\n","  content loss: 2.06208e+07\n","    style loss: 3.76592e+08\n","    total loss: 3.97213e+08\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 330714176.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 12\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 50/100\n","  content loss: 2.08204e+07\n","    style loss: 3.09894e+08\n","    total loss: 3.30714e+08\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 291504384.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 12\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 60/100\n","  content loss: 2.09704e+07\n","    style loss: 2.70534e+08\n","    total loss: 2.91504e+08\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 258219120.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 12\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 70/100\n","  content loss: 2.10962e+07\n","    style loss: 2.37123e+08\n","    total loss: 2.58219e+08\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 237364560.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 12\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 80/100\n","  content loss: 2.11889e+07\n","    style loss: 2.16176e+08\n","    total loss: 2.37365e+08\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 218785904.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 13\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 90/100\n","  content loss: 2.12929e+07\n","    style loss: 1.97493e+08\n","    total loss: 2.18786e+08\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 203571680.000000\n","  Number of iterations: 10\n","  Number of functions evaluations: 13\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 100/100\n","  content loss: 2.13592e+07\n","    style loss: 1.82212e+08\n","    total loss: 2.03572e+08\n"],"name":"stderr"}]},{"metadata":{"id":"8FgXJBo_7zWk","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}